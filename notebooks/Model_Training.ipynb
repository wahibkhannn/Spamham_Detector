{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a9b1c24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>1</td>\n",
       "      <td>Subject: works wondder\\r\\ndear sir / madam .\\r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6904</th>\n",
       "      <td>0</td>\n",
       "      <td>I dont have i shall buy one dear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4747</th>\n",
       "      <td>0</td>\n",
       "      <td>Subject: re : flow volumes at oxy gladewater ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7173</th>\n",
       "      <td>0</td>\n",
       "      <td>How much she payed. Suganya.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8175</th>\n",
       "      <td>0</td>\n",
       "      <td>\\HEY BABE! FAR 2 SPUN-OUT 2 SPK AT DA MO... DE...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                            Message\n",
       "1386      1  Subject: works wondder\\r\\ndear sir / madam .\\r...\n",
       "6904      0                   I dont have i shall buy one dear\n",
       "4747      0  Subject: re : flow volumes at oxy gladewater ,...\n",
       "7173      0                       How much she payed. Suganya.\n",
       "8175      0  \\HEY BABE! FAR 2 SPUN-OUT 2 SPK AT DA MO... DE..."
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "df = pd.read_csv('spamham.csv')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "22980494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>subject enron methanol meter follow note gave ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>subject hpl nom january see attached file hpln...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>subject neon retreat ho ho ho around wonderful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>subject photoshop window office cheap main tre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>subject indian spring deal book teco pvr reven...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            Message\n",
       "0      0  subject enron methanol meter follow note gave ...\n",
       "1      0  subject hpl nom january see attached file hpln...\n",
       "2      0  subject neon retreat ho ho ho around wonderful...\n",
       "3      1  subject photoshop window office cheap main tre...\n",
       "4      0  subject indian spring deal book teco pvr reven..."
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text_lemmatize(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\n', ' ', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s$!]', '', text)\n",
    "    words = text.split()\n",
    "    words = [w for w in words if w not in stop_words]\n",
    "    words = [lemmatizer.lemmatize(w) for w in words]  # lemmatize instead of stem\n",
    "    return \" \".join(words)\n",
    "\n",
    "# cleaning the messages column by filtering out stopword so that we get better model performance\n",
    "df['Message'] = df['Message'].apply(clean_text_lemmatize)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dedb6a2",
   "metadata": {},
   "source": [
    "Difference in Stemming and Lemmatization :\n",
    "| Original | Stemmed (Porter) | Lemmatized |\n",
    "| -------- | ---------------- | ---------- |\n",
    "| running  | run              | run        |\n",
    "| better   | better           | good       |\n",
    "| devices  | devic            | device     |\n",
    "| eligible | elig             | eligible   |\n",
    "| went     | went             | go         |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d83836d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "459\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9744, 2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.duplicated().sum())\n",
    "df.drop_duplicates(keep='first', inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "74104a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9744, 17722) (9744,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "f = TfidfVectorizer(ngram_range=(1,2), min_df=5, max_df=0.9, sublinear_tf=True)\n",
    "X = f.fit_transform(df['Message'])\n",
    "y = df.label\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "81e54644",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.27, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1224e88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "list_alpha = np.arange(1/100000, 5, 0.019) # start from 0.0001, increasing by 0.11 per step, until just before 20 \n",
    "# list_alpha is a numpy array with x elements\n",
    "\n",
    "train_score = np.zeros(len(list_alpha))\n",
    "test_score = np.zeros(len(list_alpha))\n",
    "recall_test = np.zeros(len(list_alpha))\n",
    "precision_test = np.zeros(len(list_alpha))\n",
    "f1_test = np.zeros(len(list_alpha))\n",
    "count = 0\n",
    "for alpha in list_alpha:\n",
    "    nb = naive_bayes.MultinomialNB(alpha=alpha)\n",
    "    nb.fit(X_train, y_train)\n",
    "    y_pred = nb.predict(X_test)\n",
    "    train_score[count] = nb.score(X_train, y_train)\n",
    "    test_score[count] = nb.score(X_test, y_test)\n",
    "    recall_test[count] = recall_score(y_test, y_pred)\n",
    "    precision_test[count] = precision_score(y_test, y_pred)\n",
    "    f1_test[count] = f1_score(y_test, y_pred)\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fb86d7fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((264,), (264,))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_score.shape, precision_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7d055eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test Recall</th>\n",
       "      <th>Test Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.988050</td>\n",
       "      <td>0.961992</td>\n",
       "      <td>0.931579</td>\n",
       "      <td>0.896959</td>\n",
       "      <td>0.913941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01901</td>\n",
       "      <td>0.984817</td>\n",
       "      <td>0.966173</td>\n",
       "      <td>0.940351</td>\n",
       "      <td>0.906937</td>\n",
       "      <td>0.923342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.03801</td>\n",
       "      <td>0.984676</td>\n",
       "      <td>0.967693</td>\n",
       "      <td>0.936842</td>\n",
       "      <td>0.915952</td>\n",
       "      <td>0.926279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.05701</td>\n",
       "      <td>0.983692</td>\n",
       "      <td>0.966933</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.924414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.07601</td>\n",
       "      <td>0.983129</td>\n",
       "      <td>0.967313</td>\n",
       "      <td>0.931579</td>\n",
       "      <td>0.918685</td>\n",
       "      <td>0.925087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>4.92101</td>\n",
       "      <td>0.863630</td>\n",
       "      <td>0.851387</td>\n",
       "      <td>0.314035</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.477971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>4.94001</td>\n",
       "      <td>0.863068</td>\n",
       "      <td>0.850627</td>\n",
       "      <td>0.310526</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.473896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>4.95901</td>\n",
       "      <td>0.862786</td>\n",
       "      <td>0.850627</td>\n",
       "      <td>0.310526</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.473896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>4.97801</td>\n",
       "      <td>0.862224</td>\n",
       "      <td>0.849867</td>\n",
       "      <td>0.307018</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.469799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>4.99701</td>\n",
       "      <td>0.862084</td>\n",
       "      <td>0.849487</td>\n",
       "      <td>0.305263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.467742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>264 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       alpha  Train Accuracy  Test Accuracy  Test Recall  Test Precision  \\\n",
       "0    0.00001        0.988050       0.961992     0.931579        0.896959   \n",
       "1    0.01901        0.984817       0.966173     0.940351        0.906937   \n",
       "2    0.03801        0.984676       0.967693     0.936842        0.915952   \n",
       "3    0.05701        0.983692       0.966933     0.933333        0.915663   \n",
       "4    0.07601        0.983129       0.967313     0.931579        0.918685   \n",
       "..       ...             ...            ...          ...             ...   \n",
       "259  4.92101        0.863630       0.851387     0.314035        1.000000   \n",
       "260  4.94001        0.863068       0.850627     0.310526        1.000000   \n",
       "261  4.95901        0.862786       0.850627     0.310526        1.000000   \n",
       "262  4.97801        0.862224       0.849867     0.307018        1.000000   \n",
       "263  4.99701        0.862084       0.849487     0.305263        1.000000   \n",
       "\n",
       "     F1 Score  \n",
       "0    0.913941  \n",
       "1    0.923342  \n",
       "2    0.926279  \n",
       "3    0.924414  \n",
       "4    0.925087  \n",
       "..        ...  \n",
       "259  0.477971  \n",
       "260  0.473896  \n",
       "261  0.473896  \n",
       "262  0.469799  \n",
       "263  0.467742  \n",
       "\n",
       "[264 rows x 6 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = np.matrix(np.c_[list_alpha, train_score, test_score, recall_test, precision_test, f1_test])\n",
    "models = pd.DataFrame(data=matrix, columns=['alpha', 'Train Accuracy', 'Test Accuracy', 'Test Recall', 'Test Precision', 'F1 Score'])\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "82907438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test Recall</th>\n",
       "      <th>Test Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.20901</td>\n",
       "      <td>0.979615</td>\n",
       "      <td>0.971114</td>\n",
       "      <td>0.924561</td>\n",
       "      <td>0.941071</td>\n",
       "      <td>0.932743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      alpha  Train Accuracy  Test Accuracy  Test Recall  Test Precision  \\\n",
       "11  0.20901        0.979615       0.971114     0.924561        0.941071   \n",
       "\n",
       "    F1 Score  \n",
       "11  0.932743  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_Accuracy_winner = models[models['Test Accuracy']==models['Test Accuracy'].max()]\n",
    "test_Accuracy_winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3556d878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alpha             0.209010\n",
       "Train Accuracy    0.979615\n",
       "Test Accuracy     0.971114\n",
       "Test Recall       0.924561\n",
       "Test Precision    0.941071\n",
       "F1 Score          0.932743\n",
       "Name: 11, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winner_f1 = models.loc[models['F1 Score'].idxmax()]\n",
    "winner_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90722c7",
   "metadata": {},
   "source": [
    "#### **Note:**\n",
    "\n",
    "The Model with the highest **Test Accuracy and F1 score** is the **same** with **alpha=0.20901**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d9f86e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9711136450019004\n",
      "f1 score: 0.9327433628318584\n",
      "Confusion Matrix\n",
      " [[2028   33]\n",
      " [  43  527]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "model = naive_bayes.MultinomialNB(alpha=0.20901)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print('Accuracy', accuracy_score(y_test, y_pred))\n",
    "print('f1 score:',f1_score(y_test, y_pred))\n",
    "print('Confusion Matrix\\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "51b9fbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "model_list = {\n",
    "    'Multinomial NB': MultinomialNB(alpha=0.20901),\n",
    "    'Logistic Regression Clf': LogisticRegression(),\n",
    "    'Support Vector Classifier': SVC(kernel='linear', C=1)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209e8624",
   "metadata": {},
   "source": [
    "- We will create a generic function to check each model's performance and then compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a226ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(X, y, models):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.27, random_state=42)\n",
    "    models_list = []\n",
    "    scores = []\n",
    "    f1_scores = []\n",
    "    for i in range(len(list(models))):\n",
    "        model = list(models.values())[i]\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        score = accuracy_score(y_test, y_pred)\n",
    "        f1_sc = f1_score(y_test, y_pred)\n",
    "\n",
    "        model_name = list(models.keys())[i]\n",
    "        print(f'--- Score for {model_name} ---')\n",
    "        print(f'{score}')\n",
    "        models_list.append(model_name)\n",
    "        scores.append(score)\n",
    "        f1_scores.append(f1_sc)\n",
    "    print()\n",
    "\n",
    "    res = pd.DataFrame()\n",
    "    res['Model Name'] = models_list\n",
    "    res['Score'] = scores\n",
    "    res['F1 Score'] = f1_scores\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c47e6269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Score for Multinomial NB ---\n",
      "0.9711136450019004\n",
      "--- Score for Logistic Regression Clf ---\n",
      "0.9448878753325731\n",
      "--- Score for Support Vector Classifier ---\n",
      "0.9752945648042569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = evaluate_models(X, y, model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb670c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Score</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multinomial NB</td>\n",
       "      <td>0.971114</td>\n",
       "      <td>0.932743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression Clf</td>\n",
       "      <td>0.944888</td>\n",
       "      <td>0.857704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Classifier</td>\n",
       "      <td>0.975295</td>\n",
       "      <td>0.941599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model Name     Score  F1 Score\n",
       "0             Multinomial NB  0.971114  0.932743\n",
       "1    Logistic Regression Clf  0.944888  0.857704\n",
       "2  Support Vector Classifier  0.975295  0.941599"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbcce4e",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "\n",
    "- Until now, we see that SVC is giving the best results.\n",
    "Let's test it with some parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "43be5e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 5 candidates, totalling 30 fits\n",
      "{'svc__C': 1.35}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipe = Pipeline([\n",
    "    ('svc', SVC(kernel='linear'))\n",
    "])\n",
    "param = {\n",
    "    'svc__C':[1.1,1.22,1.35,1.25,1.28],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipe, param, cv=6, scoring='f1', verbose=2, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "94b21105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.976054732041049"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = grid.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "y_predicted = best_model.predict(X_test)\n",
    "accuracy_score(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "af73e9c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9432943294329433"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f924b852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9768148992778412"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.svm import SVC\n",
    "m = SVC(kernel='linear', C=1.22)\n",
    "m.fit(X_train, y_train)\n",
    "predicted = m.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "db60c685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score is:  0.9768148992778412\n",
      "F1 Score for the model is: 0.945193171608266\n",
      "[[2044   17]\n",
      " [  44  526]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      2061\n",
      "           1       0.97      0.92      0.95       570\n",
      "\n",
      "    accuracy                           0.98      2631\n",
      "   macro avg       0.97      0.96      0.97      2631\n",
      "weighted avg       0.98      0.98      0.98      2631\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print('Accuracy Score is: ',accuracy_score(y_test, predicted))\n",
    "print('F1 Score for the model is:',f1_score(y_test, predicted))\n",
    "print(confusion_matrix(y_test,predicted))\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54426af7",
   "metadata": {},
   "source": [
    "- True Negatives (TN) = 2044 → Ham correctly classified\n",
    "- False Positives (FP) = 17 → Ham misclassified as Spam\n",
    "- False Negatives (FN) = 44 → Spam misclassified as Ham\n",
    "- True Positives (TP) = 526 → Spam correctly classified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6a9d4b",
   "metadata": {},
   "source": [
    "##### Why SVC with the Same Parameters Gave Different Scores\n",
    "\n",
    "While testing SVM manually and through GridSearchCV, I noticed slight score differences even with the same parameters.\n",
    "This happens because GridSearchCV uses k-fold cross-validation (cv=5), while a manual test relies on a single train-test split.\n",
    "\n",
    "In cross-validation, the training set is divided into 5 parts; the model trains on 4 and validates on 1, repeating the process five times. The final score is the average across folds, reflecting more stable generalization performance.\n",
    "\n",
    "So, although C = 1.22 worked best on my test split, GridSearchCV found C = 1.35 slightly better on average across folds. Such variations are normal — they come from different data splits and optimization differences.\n",
    "\n",
    "In short, GridSearchCV’s result is a more reliable estimate of real-world performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8650b63",
   "metadata": {},
   "source": [
    "C controls the penalty for misclassified points:\n",
    "- High C → low tolerance for misclassification\n",
    "    - Large C (e.g., 100) The model tries very hard to classify all training points correctly.\n",
    "    - Decision boundary becomes tight and may fit noise → risk of overfitting.\n",
    "- Low C → high tolerance for misclassification\n",
    "    - The model allows some misclassifications in training.\n",
    "    - Decision boundary is smoother → better generalization, but may slightly underfit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbd19b8",
   "metadata": {},
   "source": [
    "## END-REPORT\n",
    "\n",
    "The best model is **SVC** with kernel set to 'linear' and regularization **C=1.22**\n",
    "<p> which gave us 97.68% accuracy score which is pretty amazing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2ce947",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
