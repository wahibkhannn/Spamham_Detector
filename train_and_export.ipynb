{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aebbdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml \n",
    "import importlib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eeae182e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.base import TransformerMixin, BaseEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0a4e0252",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Custom transformer for text cleaning\n",
    "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X.apply(self.clean_text)\n",
    "    \n",
    "    def clean_text(self, text):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'\\n', ' ', text)\n",
    "        text = re.sub(r'\\d+', '', text)\n",
    "        text = re.sub(r'[^\\w\\s$!]', '', text)\n",
    "        words = text.split()\n",
    "        words = [w for w in words if w not in stop_words]\n",
    "        words = [lemmatizer.lemmatize(w) for w in words]\n",
    "        return \" \".join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fe29cd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class DenseTransformer(TransformerMixin):\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c544f3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"notebooks/spamham.csv\")\n",
    "\n",
    "TEXT_COLUMN =\"Message\"\n",
    "TARGET_COLUMN =\"label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b50be63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[TEXT_COLUMN], df[TARGET_COLUMN], test_size=0.27, random_state=42)\n",
    "\n",
    "#Load model.yaml\n",
    "with open(r\"config\\model.yaml\",\"r\") as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "81df5fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_config = config['grid_search']\n",
    "model_config = config['model_selection']\n",
    "\n",
    "best_model = None\n",
    "best_score = 0\n",
    "best_model_name =\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6a7188a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: MultinomialNB\n",
      "Starting training...\n",
      "Fitting 6 folds for each of 5 candidates, totalling 30 fits\n",
      "Best parameters for MultinomialNB: {'classifier__alpha': 0.01}\n",
      "Best cross-validation score for MultinomialNB: 0.9618692049206244\n",
      "Training model: GaussianNB\n",
      "Starting training...\n",
      "Fitting 6 folds for each of 3 candidates, totalling 18 fits\n",
      "Best parameters for GaussianNB: {'classifier__var_smoothing': 0.059096}\n",
      "Best cross-validation score for GaussianNB: 0.914742128294196\n",
      "Training model: SVC\n",
      "Starting training...\n",
      "Fitting 6 folds for each of 5 candidates, totalling 30 fits\n",
      "Best parameters for SVC: {'classifier__C': 1.22, 'classifier__kernel': 'linear'}\n",
      "Best cross-validation score for SVC: 0.9740872878390542\n"
     ]
    }
   ],
   "source": [
    "# Loop through the defined models\n",
    "for module_key, model_def in model_config.items():\n",
    "    module_name = model_def['module']\n",
    "    class_name = model_def[\"class\"]\n",
    "    params_grid = model_def[\"search_param_grid\"]\n",
    "\n",
    "    # Dynamically import the module and class\n",
    "    model_class = getattr(importlib.import_module(module_name), class_name)\n",
    "    model_instance = model_class()\n",
    "    print(f\"Training model: {class_name}\")\n",
    "\n",
    "    requires_dense = class_name in [\"GaussianNB\"]\n",
    "\n",
    "    steps = [(\"preprocess\", TextPreprocessor()),\n",
    "             (\"tfidf\", TfidfVectorizer(ngram_range=(1,2), min_df=5, max_df=0.9, sublinear_tf=True))\n",
    "            ]\n",
    "    \n",
    "    if requires_dense:\n",
    "        steps.append((\"to_dense\", DenseTransformer()))\n",
    "    steps.append((\"classifier\", model_instance))\n",
    "    pipeline = Pipeline(steps)\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid={f\"classifier__{key}\": value for key, value in params_grid.items()},\n",
    "        cv = grid_config['params']['cv'],\n",
    "        n_jobs=-1,\n",
    "        verbose=grid_config['params']['verbose']\n",
    "    )\n",
    "\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    \n",
    "    grid_search.fit(X_train,y_train)\n",
    "    print(f\"Best parameters for {class_name}: {grid_search.best_params_}\")\n",
    "    print(f\"Best cross-validation score for {class_name}: {grid_search.best_score_}\")\n",
    "\n",
    "    if grid_search.best_score_ > best_score:\n",
    "        best_score = grid_search.best_score_\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_model_name = class_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "389dbafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: SVC with F1 score: 0.9387069689336692 and accuracy: 0.973502722323049\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, classification_report, accuracy_score, r2_score\n",
    "y_pred = best_model.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"Best model: {best_model_name} with F1 score: {f1} and accuracy: {accuracy_score(y_test,y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8c8945c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved: SVC\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(best_model, \"artifact/best_model.pkl\")\n",
    "print(f\"Best model saved: {best_model_name}\")\n",
    "\n",
    "\n",
    "# Training model: MultinomialNB\n",
    "# Starting training...\n",
    "\n",
    "# Training model: MultinomialNB\n",
    "# Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
    "# Best parameters for MultinomialNB: {'classifier__alpha': 0.05}\n",
    "# Best cross-validation score for MultinomialNB: 0.9664341186598817\n",
    "# Training model: GaussianNB\n",
    "# Starting training...\n",
    "\n",
    "# Training model: GaussianNB\n",
    "# Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
    "# Best parameters for GaussianNB: {'classifier__var_smoothing': 0.059096}\n",
    "# Best cross-validation score for GaussianNB: 0.9219919679438927\n",
    "# Training model: SVC\n",
    "# Starting training...\n",
    "\n",
    "# Training model: SVC\n",
    "# Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
    "# Best parameters for SVC: {'classifier__C': 1.22, 'classifier__kernel': 'linear'}\n",
    "# Best cross-validation score for SVC: 0.977712802159911"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2223225",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
